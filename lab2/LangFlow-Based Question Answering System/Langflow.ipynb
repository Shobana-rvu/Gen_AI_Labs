{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Langflow Logic"
      ],
      "metadata": {
        "id": "cfQ_DRpN4wND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers gradio --quiet\n"
      ],
      "metadata": {
        "id": "-XUpmf8r2Ipr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# Load Question Answering pipeline\n",
        "qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"distilbert-base-cased-distilled-squad\"\n",
        ")\n",
        "\n",
        "# Context (knowledge base)\n",
        "context = \"\"\"\n",
        "A database is an organized collection of data that is stored and accessed electronically.\n",
        "DBMS stands for Database Management System and is used to manage databases.\n",
        "SQL stands for Structured Query Language and is used to interact with databases.\n",
        "A primary key uniquely identifies each record in a table.\n",
        "A foreign key links one table to another table.\n",
        "\"\"\"\n",
        "\n",
        "def answer_question(question):\n",
        "    result = qa_pipeline(\n",
        "        question=question,\n",
        "        context=context\n",
        "    )\n",
        "    return result[\"answer\"]\n",
        "\n",
        "gr.Interface(\n",
        "    fn=answer_question,\n",
        "    inputs=gr.Textbox(label=\"Enter your question\"),\n",
        "    outputs=gr.Textbox(label=\"Answer\"),\n",
        "    title=\"Transformers-based Q&A (LangFlow Logic)\",\n",
        "    description=\"Basic lab-level Question Answering using Hugging Face Transformers\"\n",
        ").launch()\n",
        "\n"
      ],
      "metadata": {
        "id": "6wjAFrXr2J4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# LLM component\n",
        "llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
        "\n",
        "# Prompt component\n",
        "def prompt_template(user_input):\n",
        "    return f\"You are a helpful student assistant.\\nQuestion: {user_input}\"\n",
        "\n",
        "# Langflow logical executor\n",
        "def run_langflow(user_input):\n",
        "    prompt = prompt_template(user_input)\n",
        "    response = llm(prompt, max_length=150)\n",
        "    return response[0][\"generated_text\"]\n",
        "\n",
        "# Test\n",
        "print(run_langflow(\"Explain normalization in DBMS\"))\n"
      ],
      "metadata": {
        "id": "M59UgSyc1tly"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}