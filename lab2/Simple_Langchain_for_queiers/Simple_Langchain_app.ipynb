{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Langchain using hugging face"
      ],
      "metadata": {
        "id": "FDD-MLpArhUL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikH_KgQJ7eca"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community langchain-core transformers gradio accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH5PEMkj8eqQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community langchain-core transformers gradio accelerate sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9A3C4-187zZ"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYO_mfHt89sJ"
      },
      "outputs": [],
      "source": [
        "hf_pipeline = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-small\",\n",
        "    max_new_tokens=100\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqWhILYd9AwE"
      },
      "outputs": [],
      "source": [
        "# Wrap HF pipeline into LangChain Runnable\n",
        "llm = RunnableLambda(lambda x: hf_pipeline(x)[0][\"generated_text\"])\n",
        "\n",
        "# Ensure output is always string\n",
        "chain = llm | StrOutputParser()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2VVjA1Y9DKV"
      },
      "outputs": [],
      "source": [
        "def chat(user_input):\n",
        "    return chain.invoke(user_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNv_plye9GLT"
      },
      "outputs": [],
      "source": [
        "iface = gr.Interface(\n",
        "    fn=chat,\n",
        "    inputs=gr.Textbox(label=\"user_input\", placeholder=\"Ask something...\"),\n",
        "    outputs=gr.Textbox(label=\"output\"),\n",
        "    title=\"Simple LangChain App\",\n",
        "    description=\"LangChain (Runnable) + Hugging Face + Gradio\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}