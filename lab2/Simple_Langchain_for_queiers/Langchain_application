!pip install -q langchain langchain-community langchain-core transformers gradio accelerate

!pip install -q langchain langchain-community langchain-core transformers gradio accelerate sentencepiece

from transformers import pipeline
from langchain_core.runnables import RunnableLambda
from langchain_core.output_parsers import StrOutputParser
import gradio as gr

hf_pipeline = pipeline(
    "text2text-generation",
    model="google/flan-t5-small",
    max_new_tokens=100
)


# Wrap HF pipeline into LangChain Runnable
llm = RunnableLambda(lambda x: hf_pipeline(x)[0]["generated_text"])

# Ensure output is always string
chain = llm | StrOutputParser()


def chat(user_input):
    return chain.invoke(user_input)

iface = gr.Interface(
    fn=chat,
    inputs=gr.Textbox(label="user_input", placeholder="Ask something..."),
    outputs=gr.Textbox(label="output"),
    title="Simple LangChain App",
    description="LangChain (Runnable) + Hugging Face + Gradio"
)

iface.launch()
